{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAyi20ln8jz_"
      },
      "source": [
        "\n",
        " **Nishant Kumar, B.Tech 3rd Year in Mathematics and Computing, IIT Goa.**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetching dataset from kaggle"
      ],
      "metadata": {
        "id": "3Vw6ByZL7bsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "xeEIHgfKBcEF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "9Gx_Hg4aBw8T",
        "outputId": "dfe78e7c-dbf3-40a4-8d7c-c3101c5a196e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-25e223b2-4190-4478-8922-2a2a077a3199\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-25e223b2-4190-4478-8922-2a2a077a3199\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nishant19041\",\"key\":\"d5974d6732a5cc8837c5f160e013a130\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ffURJBMiBw29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5d8e2f-a238-476d-e420-2f0019962520"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "veRP4ugPBwvV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zybRuHDsBwXt",
        "outputId": "9901f105-1497-404f-9ec0-9b6812e84071"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "zZGG_Yw8CAhK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUF6s_A1CAUE",
        "outputId": "c094a865-32a3-46c7-c92c-88606c90d546"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                       title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "datasets/ankanhore545/cost-of-living-index-2022                           Cost of Living Index 2022                           176KB  2022-03-26 04:56:04           1570         23  1.0              \n",
            "datasets/piterfm/2022-ukraine-russian-war                                 2022 Ukraine Russia War                               2KB  2022-04-04 09:04:10           4793        304  1.0              \n",
            "datasets/kamilpytlak/personal-key-indicators-of-heart-disease             Personal Key Indicators of Heart Disease              3MB  2022-02-16 10:18:03           7345        162  1.0              \n",
            "datasets/kuchhbhi/latest-laptop-price-list                                Laptop Specs and latest price                        18KB  2022-04-03 17:41:17            778         23  1.0              \n",
            "datasets/prasertk/historical-commodity-prices-from-20002022               Major commodity prices from 2000-2022               388KB  2022-03-31 05:55:38            487         17  1.0              \n",
            "datasets/timmofeyy/-tesla-daily-stocks-prices                             ðŸš— Tesla Daily Stocks Prices                          57KB  2022-03-29 12:55:27            552         27  1.0              \n",
            "datasets/xhlulu/cpc-codes                                                 Cooperative Patent Classification Codes Meaning       5MB  2022-03-22 03:04:36            254         59  1.0              \n",
            "datasets/ivanchvez/causes-of-death-our-world-in-data                      Causes of Death - Our World In Data                   1MB  2022-03-29 18:35:21            638         26  0.9705882        \n",
            "datasets/prasertk/healthy-lifestyle-cities-report-2021                    Healthy Lifestyle Cities Report 2021                  2KB  2022-03-03 00:26:02           3727        105  1.0              \n",
            "datasets/timmofeyy/-fire-cases-in-uk-within-last-3-years                  ðŸ”¥ Fire Cases in UK within last 3 Years               22MB  2022-03-30 20:49:24            242         13  1.0              \n",
            "datasets/ajaypalsinghlo/world-happiness-report-2022                       world happiness report 2022                           5KB  2022-03-21 13:41:15           1311         38  0.9705882        \n",
            "datasets/vardhansiramdasu/fraudulent-transactions-prediction              Fraudulent Transactions Prediction                  178MB  2022-03-21 16:08:45            878         37  1.0              \n",
            "datasets/vivek468/superstore-dataset-final                                Superstore Dataset                                  550KB  2022-02-17 11:33:07           5607        128  1.0              \n",
            "datasets/prasertk/sunshine-duration-by-city                               Sunshine duration by city                            15KB  2022-03-29 01:57:44            411         21  1.0              \n",
            "datasets/zgrcemta/world-gdpgdp-gdp-per-capita-and-annual-growths          World GDP(GDP, GDP per capita, and annual growths)  556KB  2022-03-19 17:47:43            686         21  0.9411765        \n",
            "datasets/ashishjangra27/ted-talks                                         TED Talks                                           298KB  2022-02-23 15:16:08           3298        144  1.0              \n",
            "datasets/equinxx/spotify-top-50-songs-in-2021                             Spotify top 50 songs in 2021                          4KB  2022-03-17 22:59:45           1979         57  1.0              \n",
            "datasets/pranalibose/amazon-seller-order-status-prediction                Amazon Seller - Order Status Prediction              23KB  2022-02-26 06:31:07           3380         88  0.88235295       \n",
            "datasets/mrdaniilak/russia-real-estate-2021                               Russia Real Estate 2021                             276MB  2022-03-29 23:21:10            224         22  1.0              \n",
            "datasets/soumyadiptadas/students-math-score-for-different-teaching-style  Student's math score for different teaching style     2KB  2022-02-23 12:36:06           3904         74  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c house-prices-advanced-regression-techniques"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMpw7LiVCEyL",
        "outputId": "bcdc81b4-f2bd-4314-cd39-fa39ea4a1d53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading house-prices-advanced-regression-techniques.zip to /content\n",
            "\r  0% 0.00/199k [00:00<?, ?B/s]\n",
            "\r100% 199k/199k [00:00<00:00, 47.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip house-prices-advanced-regression-techniques.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA_fSmlyCHyD",
        "outputId": "bcb2a45d-646e-47b3-bb02-cc33a13ecb9b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  house-prices-advanced-regression-techniques.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Qy7voQ8j0E"
      },
      "source": [
        "#### First let us import the required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "I1WY_ol18j0E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import Ridge,Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGbXNl5h8j0G"
      },
      "source": [
        "# Data Understanding, Preparation and EDA "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AVpwa9C8j0G"
      },
      "source": [
        "#### Let us read the given Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "owRTDAws8j0H"
      },
      "outputs": [],
      "source": [
        "houses_data = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "gzdm5zcf8j0H",
        "outputId": "f1949197-bee2-480b-f8a2-16e0db5e8a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c05c34d6-f136-4618-81b3-4c9c343d8944\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c05c34d6-f136-4618-81b3-4c9c343d8944')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c05c34d6-f136-4618-81b3-4c9c343d8944 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c05c34d6-f136-4618-81b3-4c9c343d8944');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "houses_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTgW-xMr8j0I",
        "outputId": "0ff777a0-2db3-45ec-9496-019d6980821d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 81)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "houses_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKt-I6ZO8j0J",
        "outputId": "6488c5d3-e1c3-4000-dc88-d63b14704d2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Id',\n",
              " 'MSSubClass',\n",
              " 'MSZoning',\n",
              " 'LotFrontage',\n",
              " 'LotArea',\n",
              " 'Street',\n",
              " 'Alley',\n",
              " 'LotShape',\n",
              " 'LandContour',\n",
              " 'Utilities',\n",
              " 'LotConfig',\n",
              " 'LandSlope',\n",
              " 'Neighborhood',\n",
              " 'Condition1',\n",
              " 'Condition2',\n",
              " 'BldgType',\n",
              " 'HouseStyle',\n",
              " 'OverallQual',\n",
              " 'OverallCond',\n",
              " 'YearBuilt',\n",
              " 'YearRemodAdd',\n",
              " 'RoofStyle',\n",
              " 'RoofMatl',\n",
              " 'Exterior1st',\n",
              " 'Exterior2nd',\n",
              " 'MasVnrType',\n",
              " 'MasVnrArea',\n",
              " 'ExterQual',\n",
              " 'ExterCond',\n",
              " 'Foundation',\n",
              " 'BsmtQual',\n",
              " 'BsmtCond',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtFinSF1',\n",
              " 'BsmtFinType2',\n",
              " 'BsmtFinSF2',\n",
              " 'BsmtUnfSF',\n",
              " 'TotalBsmtSF',\n",
              " 'Heating',\n",
              " 'HeatingQC',\n",
              " 'CentralAir',\n",
              " 'Electrical',\n",
              " '1stFlrSF',\n",
              " '2ndFlrSF',\n",
              " 'LowQualFinSF',\n",
              " 'GrLivArea',\n",
              " 'BsmtFullBath',\n",
              " 'BsmtHalfBath',\n",
              " 'FullBath',\n",
              " 'HalfBath',\n",
              " 'BedroomAbvGr',\n",
              " 'KitchenAbvGr',\n",
              " 'KitchenQual',\n",
              " 'TotRmsAbvGrd',\n",
              " 'Functional',\n",
              " 'Fireplaces',\n",
              " 'FireplaceQu',\n",
              " 'GarageType',\n",
              " 'GarageYrBlt',\n",
              " 'GarageFinish',\n",
              " 'GarageCars',\n",
              " 'GarageArea',\n",
              " 'GarageQual',\n",
              " 'GarageCond',\n",
              " 'PavedDrive',\n",
              " 'WoodDeckSF',\n",
              " 'OpenPorchSF',\n",
              " 'EnclosedPorch',\n",
              " '3SsnPorch',\n",
              " 'ScreenPorch',\n",
              " 'PoolArea',\n",
              " 'PoolQC',\n",
              " 'Fence',\n",
              " 'MiscFeature',\n",
              " 'MiscVal',\n",
              " 'MoSold',\n",
              " 'YrSold',\n",
              " 'SaleType',\n",
              " 'SaleCondition',\n",
              " 'SalePrice']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Storing all the Column Names in a List\n",
        "houses_data.columns.tolist() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "LKfiyPIi8j0K",
        "outputId": "286f56cf-1287-4634-f7e2-5314d77b8c3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
              "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
              "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
              "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
              "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
              "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
              "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
              "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
              "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
              "\n",
              "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
              "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
              "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
              "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
              "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
              "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
              "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
              "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
              "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b175846-4af4-432a-ba72-a95bee6e70dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b175846-4af4-432a-ba72-a95bee6e70dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b175846-4af4-432a-ba72-a95bee6e70dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b175846-4af4-432a-ba72-a95bee6e70dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "houses_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C-q50fj8j0K",
        "outputId": "fab7386d-53e8-4e48-dcf8-4571fbaefff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ]
        }
      ],
      "source": [
        "houses_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3-C9YOwU8j0L"
      },
      "outputs": [],
      "source": [
        "# Checking the Number of Missing Values in each Column of the DataFrame\n",
        "no_of_null_columwise = houses_data.isnull().sum() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYaMaqot8j0L",
        "outputId": "aeea4118-fd70-462d-96ee-f302d36cc6d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LotFrontage      259\n",
              "Alley           1369\n",
              "MasVnrType         8\n",
              "MasVnrArea         8\n",
              "BsmtQual          37\n",
              "BsmtCond          37\n",
              "BsmtExposure      38\n",
              "BsmtFinType1      37\n",
              "BsmtFinType2      38\n",
              "Electrical         1\n",
              "FireplaceQu      690\n",
              "GarageType        81\n",
              "GarageYrBlt       81\n",
              "GarageFinish      81\n",
              "GarageQual        81\n",
              "GarageCond        81\n",
              "PoolQC          1453\n",
              "Fence           1179\n",
              "MiscFeature     1406\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Checking which Columns have atleast one Null Value\n",
        "no_of_null_columwise[lambda x : x>0] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XphtScpj8j0M"
      },
      "source": [
        "## Dealing with NaN Values \n",
        "\n",
        "**1) From the above data, It can be clearly seen that Out of 1460 Rows, the Columns `Alley, PoolQC, Fence, MiscFeature` have most of the Rows with Null Values.** \n",
        "\n",
        "**2) `FireplaceQu` Column has Half amount as Null Values.**\n",
        "\n",
        "**3) `Id` Column is also not required for our analysis.**\n",
        "\n",
        "*So It is advisable to remove them from our Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kTSHb4ul8j0M"
      },
      "outputs": [],
      "source": [
        "# Dropping the Columns from the Dataframe\n",
        "\n",
        "houses_data.drop(['Id','Alley', 'PoolQC', 'Fence', 'MiscFeature','FireplaceQu'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB7JWMe78j0M",
        "outputId": "8acb0310-5de7-4ab0-979a-7611f2aad214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "houses_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YCZql_YH8j0N"
      },
      "outputs": [],
      "source": [
        "# Now let us check remaining Columns with Null Values\n",
        "\n",
        "columns_with_null =  houses_data.isnull().sum()[lambda x : x>0].index.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5VZHJu78j0N",
        "outputId": "3266631a-6ff7-4623-8d33-17135a4bb1de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LotFrontage',\n",
              " 'MasVnrType',\n",
              " 'MasVnrArea',\n",
              " 'BsmtQual',\n",
              " 'BsmtCond',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtFinType2',\n",
              " 'Electrical',\n",
              " 'GarageType',\n",
              " 'GarageYrBlt',\n",
              " 'GarageFinish',\n",
              " 'GarageQual',\n",
              " 'GarageCond']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "columns_with_null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiwLsXYv8j0O"
      },
      "source": [
        "### Replacing the NaN columns with MODE of the Corrseponding Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HTsDKtw98j0O"
      },
      "outputs": [],
      "source": [
        "for col in columns_with_null :\n",
        "    houses_data[col].fillna(houses_data[col].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjrm4l5U8j0Q",
        "outputId": "b4c95f43-f71b-4c39-b339-b29d5c1f1943"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Finally, Let us Check for Missing Values in each Column of the DataFrame\n",
        "\n",
        "no_of_null_columwise = houses_data.isnull().sum() \n",
        "no_of_null_columwise[lambda x : x>0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lV4Abyk8j0R"
      },
      "source": [
        "### Now We have no more Null Values in our Dataframe !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N8837iQ8j0R"
      },
      "source": [
        "## Data Encoding ( Categorical to Numerical values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baxqmmrq8j0R",
        "outputId": "bfe7028a-3fc3-4e80-e57d-b791ee5a39cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
              "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
              "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
              "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
              "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
              "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
              "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
              "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
              "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
              "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
              "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
              "       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish',\n",
              "       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
              "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
              "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
              "       'SaleCondition', 'SalePrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "houses_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiIPkuBs8j0S",
        "outputId": "c08ae4ce-e668-4264-a29e-9d59e5126501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MSZoning',\n",
              " 'Street',\n",
              " 'LotShape',\n",
              " 'LandContour',\n",
              " 'Utilities',\n",
              " 'LotConfig',\n",
              " 'LandSlope',\n",
              " 'Neighborhood',\n",
              " 'Condition1',\n",
              " 'Condition2',\n",
              " 'BldgType',\n",
              " 'HouseStyle',\n",
              " 'RoofStyle',\n",
              " 'RoofMatl',\n",
              " 'Exterior1st',\n",
              " 'Exterior2nd',\n",
              " 'MasVnrType',\n",
              " 'ExterQual',\n",
              " 'ExterCond',\n",
              " 'Foundation',\n",
              " 'BsmtQual',\n",
              " 'BsmtCond',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtFinType2',\n",
              " 'Heating',\n",
              " 'HeatingQC',\n",
              " 'CentralAir',\n",
              " 'Electrical',\n",
              " 'KitchenQual',\n",
              " 'Functional',\n",
              " 'GarageType',\n",
              " 'GarageFinish',\n",
              " 'GarageQual',\n",
              " 'GarageCond',\n",
              " 'PavedDrive',\n",
              " 'SaleType',\n",
              " 'SaleCondition']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Selecting the columns which have \"object\" Datatype\n",
        "\n",
        "Non_Numerical_Columns = houses_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "Non_Numerical_Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NwOTHXCL8j0S"
      },
      "outputs": [],
      "source": [
        "# Using Label Encoder to transform all the columns with the Categorical Values to Numerical Values\n",
        "\n",
        "for col in Non_Numerical_Columns:\n",
        "    lb=LabelEncoder()\n",
        "    houses_data[col]=lb.fit_transform(houses_data[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "rzzWwKDB8j0S",
        "outputId": "9d63a41b-0269-40e5-8e0a-62b9e5193302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
              "0          60         3         65.0     8450       1         3            3   \n",
              "1          20         3         80.0     9600       1         3            3   \n",
              "2          60         3         68.0    11250       1         0            3   \n",
              "3          70         3         60.0     9550       1         0            3   \n",
              "4          60         3         84.0    14260       1         0            3   \n",
              "\n",
              "   Utilities  LotConfig  LandSlope  ...  EnclosedPorch  3SsnPorch  \\\n",
              "0          0          4          0  ...              0          0   \n",
              "1          0          2          0  ...              0          0   \n",
              "2          0          4          0  ...              0          0   \n",
              "3          0          0          0  ...            272          0   \n",
              "4          0          2          0  ...              0          0   \n",
              "\n",
              "   ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \\\n",
              "0            0         0        0       2    2008         8              4   \n",
              "1            0         0        0       5    2007         8              4   \n",
              "2            0         0        0       9    2008         8              4   \n",
              "3            0         0        0       2    2006         8              0   \n",
              "4            0         0        0      12    2008         8              4   \n",
              "\n",
              "   SalePrice  \n",
              "0     208500  \n",
              "1     181500  \n",
              "2     223500  \n",
              "3     140000  \n",
              "4     250000  \n",
              "\n",
              "[5 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-218d5c3f-9c2d-4d67-8eba-986eded6b22c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>...</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-218d5c3f-9c2d-4d67-8eba-986eded6b22c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-218d5c3f-9c2d-4d67-8eba-986eded6b22c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-218d5c3f-9c2d-4d67-8eba-986eded6b22c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Now let us check dataframe whether it has only int or float !\n",
        "\n",
        "houses_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHz-jMd8j0T"
      },
      "source": [
        "## Oulier Detection and Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "PtL8KxUA8j0T",
        "outputId": "03175c22-1be7-44c9-9701-5382765cc107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MSSubClass     MSZoning  LotFrontage        LotArea       Street  \\\n",
              "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
              "mean     56.897260     3.028767    68.267123   10516.828082     0.995890   \n",
              "std      42.300571     0.632017    22.356355    9981.264932     0.063996   \n",
              "min      20.000000     0.000000    21.000000    1300.000000     0.000000   \n",
              "25%      20.000000     3.000000    60.000000    7553.500000     1.000000   \n",
              "50%      50.000000     3.000000    63.000000    9478.500000     1.000000   \n",
              "75%      70.000000     3.000000    79.000000   11601.500000     1.000000   \n",
              "max     190.000000     4.000000   313.000000  215245.000000     1.000000   \n",
              "\n",
              "          LotShape  LandContour    Utilities    LotConfig    LandSlope  ...  \\\n",
              "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000  ...   \n",
              "mean      1.942466     2.777397     0.000685     3.019178     0.062329  ...   \n",
              "std       1.409156     0.707666     0.026171     1.622634     0.276232  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     3.000000     0.000000     2.000000     0.000000  ...   \n",
              "50%       3.000000     3.000000     0.000000     4.000000     0.000000  ...   \n",
              "75%       3.000000     3.000000     0.000000     4.000000     0.000000  ...   \n",
              "max       3.000000     3.000000     1.000000     4.000000     2.000000  ...   \n",
              "\n",
              "       EnclosedPorch    3SsnPorch  ScreenPorch     PoolArea       MiscVal  \\\n",
              "count    1460.000000  1460.000000  1460.000000  1460.000000   1460.000000   \n",
              "mean       21.954110     3.409589    15.060959     2.758904     43.489041   \n",
              "std        61.119149    29.317331    55.757415    40.177307    496.123024   \n",
              "min         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
              "25%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
              "50%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
              "75%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
              "max       552.000000   508.000000   480.000000   738.000000  15500.000000   \n",
              "\n",
              "            MoSold       YrSold     SaleType  SaleCondition      SalePrice  \n",
              "count  1460.000000  1460.000000  1460.000000    1460.000000    1460.000000  \n",
              "mean      6.321918  2007.815753     7.513014       3.770548  180921.195890  \n",
              "std       2.703626     1.328095     1.552100       1.100854   79442.502883  \n",
              "min       1.000000  2006.000000     0.000000       0.000000   34900.000000  \n",
              "25%       5.000000  2007.000000     8.000000       4.000000  129975.000000  \n",
              "50%       6.000000  2008.000000     8.000000       4.000000  163000.000000  \n",
              "75%       8.000000  2009.000000     8.000000       4.000000  214000.000000  \n",
              "max      12.000000  2010.000000     8.000000       5.000000  755000.000000  \n",
              "\n",
              "[8 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed200e35-05b6-418a-9f60-aa61e5c13c20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>...</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>56.897260</td>\n",
              "      <td>3.028767</td>\n",
              "      <td>68.267123</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>0.995890</td>\n",
              "      <td>1.942466</td>\n",
              "      <td>2.777397</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>3.019178</td>\n",
              "      <td>0.062329</td>\n",
              "      <td>...</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>7.513014</td>\n",
              "      <td>3.770548</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.300571</td>\n",
              "      <td>0.632017</td>\n",
              "      <td>22.356355</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>0.063996</td>\n",
              "      <td>1.409156</td>\n",
              "      <td>0.707666</td>\n",
              "      <td>0.026171</td>\n",
              "      <td>1.622634</td>\n",
              "      <td>0.276232</td>\n",
              "      <td>...</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>1.552100</td>\n",
              "      <td>1.100854</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>190.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed200e35-05b6-418a-9f60-aa61e5c13c20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed200e35-05b6-418a-9f60-aa61e5c13c20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed200e35-05b6-418a-9f60-aa61e5c13c20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# This helping in checking the percentiles\n",
        "\n",
        "houses_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ypcMc78A8j0T"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Defining a Function which takes a Dataframe as Input and iterates over each column and \n",
        "checks whether type of Column values are int/float and then computes percentiles and \n",
        "then Caps the values of each column to avoid the Outliers!\n",
        "\"\"\"\n",
        "\n",
        "def capping_data(df):\n",
        "    for col in df.columns:\n",
        "        if (((df[col].dtype)=='float64') | ((df[col].dtype)=='int64')):\n",
        "            percentiles = df[col].quantile([0.01,0.99]).values\n",
        "            df[col][df[col] <= percentiles[0]] = percentiles[0]\n",
        "            df[col][df[col] >= percentiles[1]] = percentiles[1]\n",
        "        else:\n",
        "            df[col]=df[col]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIIRgT_R8j0T",
        "outputId": "a1e1a50c-291b-481e-f898-31d308904657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "# Calling the above function on our Dataset\n",
        "\n",
        "houses_data=capping_data(houses_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnhkMKpr8j0U"
      },
      "source": [
        "## Data Visualisation with seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwB72y6A8j0U"
      },
      "source": [
        "#### Since `LotArea` is very Important Feature, Let us analyse `LotArea` feature of the given Housing Prices Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ZiLK7NM38j0U",
        "outputId": "18d22c29-002a-49d0-a128-0dc00e0300e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f667456f810>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting the Distribution Plot along with Gaussian Kernel Density Estimate \n",
        "\n",
        "sns.distplot(houses_data['LotArea'],kde=True,bins=50,color=\"Orange\",hist_kws=dict(edgecolor=\"b\", linewidth=1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6hQxk-s8j0U",
        "outputId": "4383cd6b-f9a9-4df6-ff85-2372e60ceef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum LotArea in the data is: 1680.0\n",
            "Maximum LotArea in the data is: 37567.64000000021\n",
            "Range of LotArea is from 1680.0 to 37567.64000000021, value is 35887.64000000021\n",
            "I used a bin size of 50, so each bar corresponds to the value of: 717.7528000000042\n"
          ]
        }
      ],
      "source": [
        "print(\"Minimum LotArea in the data is:\",houses_data.LotArea.min())\n",
        "print(\"Maximum LotArea in the data is:\",houses_data.LotArea.max())\n",
        "print(\"Range of LotArea is from {} to {}, value is {}\".format(houses_data.LotArea.min(),houses_data.LotArea.max(),houses_data.LotArea.max()-houses_data.LotArea.min()))\n",
        "print(\"I used a bin size of 50, so each bar corresponds to the value of:\",(houses_data.LotArea.max()-houses_data.LotArea.min())/50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "QDcexMXZ8j0V",
        "outputId": "ff31cedb-ff68-40ed-8cee-650e9a7c5e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6672325bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting only the Histogram using Different Bin Size\n",
        "\n",
        "sns.distplot(houses_data['LotArea'],kde=False,hist=True,bins=20,color= \"Orange\",hist_kws=dict(edgecolor=\"b\", linewidth=1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "oZj7vMEk8j0V",
        "outputId": "91e3ffe8-27f5-4ac5-a849-f41bf48a1629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Value: 7553.5\n",
            "Median Value: 9478.5\n",
            "Q3 Value: 11601.5\n",
            "Upper whisker limit: 17673.5\n",
            "Lower whisker limit: 1481.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting the Box Plot \n",
        "sns.boxplot(houses_data['LotArea'],color =\"Orange\")\n",
        "\n",
        "# Evaluating the Percentiles and Interquartile range (IQR)\n",
        "Q3 = houses_data.LotArea.quantile(.75)\n",
        "Q1 = houses_data.LotArea.quantile(.25)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Finding the Median\n",
        "Median = houses_data.LotArea.median()\n",
        "print(\"Q1 Value:\",Q1)\n",
        "print(\"Median Value:\",houses_data.LotArea.median())\n",
        "print(\"Q3 Value:\",Q3)\n",
        "print(\"Upper whisker limit:\",(Q3 + 1.5*IQR))\n",
        "print(\"Lower whisker limit:\",(Q1 - 1.5*IQR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "WQ8GD27Q8j0W",
        "outputId": "3fda2d81-958f-47f7-fee7-04c9f829995e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6671d92c10>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Checking the Symmetry of the LotArea Feature\n",
        "\n",
        "sns.violinplot(x='LotArea',data=houses_data,color =\"Orange\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI-_UTQa8j0X"
      },
      "source": [
        "### Heatmaps\n",
        "Using **Correlation** to measure how strong a relationship is between two variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "x1RcfVrV8j0X",
        "outputId": "ff88fa96-92c8-491e-b802-256456684ca8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               MSSubClass  MSZoning  LotFrontage   LotArea  Street  LotShape  \\\n",
              "MSSubClass       1.000000  0.037329    -0.385564 -0.287184     NaN  0.119289   \n",
              "MSZoning         0.037329  1.000000    -0.117687 -0.067780     NaN  0.070866   \n",
              "LotFrontage     -0.385564 -0.117687     1.000000  0.436806     NaN -0.089230   \n",
              "LotArea         -0.287184 -0.067780     0.436806  1.000000     NaN -0.264898   \n",
              "Street                NaN       NaN          NaN       NaN     NaN       NaN   \n",
              "...                   ...       ...          ...       ...     ...       ...   \n",
              "MoSold          -0.013585 -0.027176     0.014152 -0.005922     NaN -0.033455   \n",
              "YrSold          -0.021407 -0.017449     0.003798 -0.035254     NaN  0.036449   \n",
              "SaleType         0.012464  0.086518    -0.037379  0.001122     NaN -0.000911   \n",
              "SaleCondition   -0.024940 -0.010380     0.067027  0.045053     NaN -0.038118   \n",
              "SalePrice       -0.088827 -0.205091     0.350964  0.386883     NaN -0.260269   \n",
              "\n",
              "               LandContour  Utilities  LotConfig  LandSlope  ...  \\\n",
              "MSSubClass       -0.002940        NaN   0.075910  -0.024344  ...   \n",
              "MSZoning         -0.026341        NaN  -0.009090  -0.014015  ...   \n",
              "LotFrontage      -0.043980        NaN  -0.149185   0.035690  ...   \n",
              "LotArea          -0.147885        NaN  -0.176358   0.269631  ...   \n",
              "Street                 NaN        NaN        NaN        NaN  ...   \n",
              "...                    ...        ...        ...        ...  ...   \n",
              "MoSold           -0.011599        NaN   0.018902   0.004384  ...   \n",
              "YrSold            0.020507        NaN  -0.005992  -0.010619  ...   \n",
              "SaleType         -0.025754        NaN   0.014325   0.054935  ...   \n",
              "SaleCondition     0.033809        NaN   0.051579  -0.039032  ...   \n",
              "SalePrice         0.013875        NaN  -0.060627   0.055685  ...   \n",
              "\n",
              "               EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea   MiscVal  \\\n",
              "MSSubClass         -0.014892  -0.034923    -0.027292       NaN -0.027886   \n",
              "MSZoning            0.134879   0.001249     0.013503       NaN  0.020872   \n",
              "LotFrontage        -0.002927   0.056581     0.044898       NaN -0.000841   \n",
              "LotArea            -0.018566   0.051020     0.095568       NaN  0.060646   \n",
              "Street                   NaN        NaN          NaN       NaN       NaN   \n",
              "...                      ...        ...          ...       ...       ...   \n",
              "MoSold             -0.024617   0.033174     0.025260       NaN  0.014196   \n",
              "YrSold             -0.005089   0.012480     0.016099       NaN  0.053430   \n",
              "SaleType           -0.014453  -0.012758     0.000431       NaN  0.004429   \n",
              "SaleCondition      -0.088401   0.000387    -0.022663       NaN  0.013882   \n",
              "SalePrice          -0.142881   0.053937     0.103556       NaN -0.059610   \n",
              "\n",
              "                 MoSold    YrSold  SaleType  SaleCondition  SalePrice  \n",
              "MSSubClass    -0.013585 -0.021407  0.012464      -0.024940  -0.088827  \n",
              "MSZoning      -0.027176 -0.017449  0.086518      -0.010380  -0.205091  \n",
              "LotFrontage    0.014152  0.003798 -0.037379       0.067027   0.350964  \n",
              "LotArea       -0.005922 -0.035254  0.001122       0.045053   0.386883  \n",
              "Street              NaN       NaN       NaN            NaN        NaN  \n",
              "...                 ...       ...       ...            ...        ...  \n",
              "MoSold         1.000000 -0.145721 -0.047386       0.013320   0.059428  \n",
              "YrSold        -0.145721  1.000000 -0.002327       0.003880  -0.029803  \n",
              "SaleType      -0.047386 -0.002327  1.000000       0.184067  -0.056446  \n",
              "SaleCondition  0.013320  0.003880  0.184067       1.000000   0.228576  \n",
              "SalePrice      0.059428 -0.029803 -0.056446       0.228576   1.000000  \n",
              "\n",
              "[75 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de3b9bd-c226-4610-b9a3-51bd680c7678\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>...</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSSubClass</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.037329</td>\n",
              "      <td>-0.385564</td>\n",
              "      <td>-0.287184</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.119289</td>\n",
              "      <td>-0.002940</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.075910</td>\n",
              "      <td>-0.024344</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014892</td>\n",
              "      <td>-0.034923</td>\n",
              "      <td>-0.027292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.027886</td>\n",
              "      <td>-0.013585</td>\n",
              "      <td>-0.021407</td>\n",
              "      <td>0.012464</td>\n",
              "      <td>-0.024940</td>\n",
              "      <td>-0.088827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>0.037329</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.117687</td>\n",
              "      <td>-0.067780</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.070866</td>\n",
              "      <td>-0.026341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.009090</td>\n",
              "      <td>-0.014015</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134879</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>0.013503</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.020872</td>\n",
              "      <td>-0.027176</td>\n",
              "      <td>-0.017449</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>-0.010380</td>\n",
              "      <td>-0.205091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>-0.385564</td>\n",
              "      <td>-0.117687</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.436806</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.089230</td>\n",
              "      <td>-0.043980</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.149185</td>\n",
              "      <td>0.035690</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002927</td>\n",
              "      <td>0.056581</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>0.014152</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>-0.037379</td>\n",
              "      <td>0.067027</td>\n",
              "      <td>0.350964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>-0.287184</td>\n",
              "      <td>-0.067780</td>\n",
              "      <td>0.436806</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.264898</td>\n",
              "      <td>-0.147885</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.176358</td>\n",
              "      <td>0.269631</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018566</td>\n",
              "      <td>0.051020</td>\n",
              "      <td>0.095568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.060646</td>\n",
              "      <td>-0.005922</td>\n",
              "      <td>-0.035254</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.045053</td>\n",
              "      <td>0.386883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Street</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MoSold</th>\n",
              "      <td>-0.013585</td>\n",
              "      <td>-0.027176</td>\n",
              "      <td>0.014152</td>\n",
              "      <td>-0.005922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.033455</td>\n",
              "      <td>-0.011599</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.018902</td>\n",
              "      <td>0.004384</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024617</td>\n",
              "      <td>0.033174</td>\n",
              "      <td>0.025260</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.014196</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.145721</td>\n",
              "      <td>-0.047386</td>\n",
              "      <td>0.013320</td>\n",
              "      <td>0.059428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YrSold</th>\n",
              "      <td>-0.021407</td>\n",
              "      <td>-0.017449</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>-0.035254</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.036449</td>\n",
              "      <td>0.020507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.005992</td>\n",
              "      <td>-0.010619</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005089</td>\n",
              "      <td>0.012480</td>\n",
              "      <td>0.016099</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053430</td>\n",
              "      <td>-0.145721</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002327</td>\n",
              "      <td>0.003880</td>\n",
              "      <td>-0.029803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleType</th>\n",
              "      <td>0.012464</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>-0.037379</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.000911</td>\n",
              "      <td>-0.025754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.014325</td>\n",
              "      <td>0.054935</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014453</td>\n",
              "      <td>-0.012758</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004429</td>\n",
              "      <td>-0.047386</td>\n",
              "      <td>-0.002327</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.184067</td>\n",
              "      <td>-0.056446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleCondition</th>\n",
              "      <td>-0.024940</td>\n",
              "      <td>-0.010380</td>\n",
              "      <td>0.067027</td>\n",
              "      <td>0.045053</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.038118</td>\n",
              "      <td>0.033809</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.051579</td>\n",
              "      <td>-0.039032</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.088401</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>-0.022663</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.013882</td>\n",
              "      <td>0.013320</td>\n",
              "      <td>0.003880</td>\n",
              "      <td>0.184067</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.228576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>-0.088827</td>\n",
              "      <td>-0.205091</td>\n",
              "      <td>0.350964</td>\n",
              "      <td>0.386883</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.260269</td>\n",
              "      <td>0.013875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.060627</td>\n",
              "      <td>0.055685</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.142881</td>\n",
              "      <td>0.053937</td>\n",
              "      <td>0.103556</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.059610</td>\n",
              "      <td>0.059428</td>\n",
              "      <td>-0.029803</td>\n",
              "      <td>-0.056446</td>\n",
              "      <td>0.228576</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de3b9bd-c226-4610-b9a3-51bd680c7678')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8de3b9bd-c226-4610-b9a3-51bd680c7678 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8de3b9bd-c226-4610-b9a3-51bd680c7678');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "houses_data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "1UjWPVty8j0Y",
        "outputId": "4e434c48-9079-471e-ba9b-435acf00f663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6671d1e790>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# HaetMap of the Correlation Matrix\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(houses_data.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tty4dq5i8j0Y"
      },
      "source": [
        "# Model Building and Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apbeB8d-8j0Y"
      },
      "source": [
        "###### For Building the Model, We first need to define the `Dependent` and `Independent` Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urhuxnYk8j0Y"
      },
      "source": [
        "###### Independent Variable is any how fixed that is `SalePrice` of the House\n",
        "###### But While choosing the **Dependent** Variables for estimating the `SalePrice` Both the technical and business aspects must be considered.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGyUuDc-8j0Z",
        "outputId": "46fc8d99-1b01-4d04-d39d-fe2402b5a054"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[208500.],\n",
              "       [181500.],\n",
              "       [223500.],\n",
              "       ...,\n",
              "       [266500.],\n",
              "       [142125.],\n",
              "       [147500.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Independent Variable\n",
        "Y = houses_data[['SalePrice']].values\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iODGGDU18j0Z",
        "outputId": "6cf71103-aa0d-40fb-cbd3-60cdd9fe85d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  60.,    3.,   65., ..., 2008.,    8.,    4.],\n",
              "       [  20.,    3.,   80., ..., 2007.,    8.,    4.],\n",
              "       [  60.,    3.,   68., ..., 2008.,    8.,    4.],\n",
              "       ...,\n",
              "       [  70.,    3.,   66., ..., 2010.,    8.,    4.],\n",
              "       [  20.,    3.,   68., ..., 2010.,    8.,    4.],\n",
              "       [  20.,    3.,   75., ..., 2008.,    8.,    4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Dependent Variables\n",
        "X = houses_data.loc[:, houses_data.columns != 'SalePrice'].values\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BpnJsrMY8j0Z"
      },
      "outputs": [],
      "source": [
        "# Splitting the Data in Training and Testing Sets\n",
        "\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state= 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMcBcF2J8j0Z"
      },
      "source": [
        "### Ridge Regression \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWKUqHJ98j0Z",
        "outputId": "31e77625-7246-46de-c10e-cd016849c0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.75505e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 1e-15 \t-> R2_score is : 0.8841\n",
            "When Lambda (Aplha) value is : 1e-13 \t-> R2_score is : 0.8841\n",
            "When Lambda (Aplha) value is : 1e-11 \t-> R2_score is : 0.8841\n",
            "When Lambda (Aplha) value is : 1e-09 \t-> R2_score is : 0.8841\n",
            "When Lambda (Aplha) value is : 1e-07 \t-> R2_score is : 0.8841\n",
            "When Lambda (Aplha) value is : 1e-05 \t-> R2_score is : 0.88409\n",
            "When Lambda (Aplha) value is : 0.0001 \t-> R2_score is : 0.88406\n",
            "When Lambda (Aplha) value is : 0.001 \t-> R2_score is : 0.88419\n",
            "When Lambda (Aplha) value is : 0.01 \t-> R2_score is : 0.88722\n",
            "When Lambda (Aplha) value is : 0.1 \t-> R2_score is : 0.88874\n",
            "When Lambda (Aplha) value is : 0.2 \t-> R2_score is : 0.88633\n",
            "When Lambda (Aplha) value is : 0.3 \t-> R2_score is : 0.88329\n",
            "When Lambda (Aplha) value is : 0.3 \t-> R2_score is : 0.88329\n",
            "When Lambda (Aplha) value is : 0.4 \t-> R2_score is : 0.88005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.5 \t-> R2_score is : 0.87671\n",
            "When Lambda (Aplha) value is : 0.7 \t-> R2_score is : 0.86998\n",
            "When Lambda (Aplha) value is : 0.9 \t-> R2_score is : 0.86324\n",
            "When Lambda (Aplha) value is : 1 \t-> R2_score is : 0.85989\n",
            "When Lambda (Aplha) value is : 2.5 \t-> R2_score is : 0.81105\n",
            "When Lambda (Aplha) value is : 3 \t-> R2_score is : 0.79536\n",
            "When Lambda (Aplha) value is : 5 \t-> R2_score is : 0.7358\n",
            "When Lambda (Aplha) value is : 10 \t-> R2_score is : 0.61191\n",
            "When Lambda (Aplha) value is : 20 \t-> R2_score is : 0.45019\n",
            "When Lambda (Aplha) value is : 30 \t-> R2_score is : 0.354\n",
            "When Lambda (Aplha) value is : 40 \t-> R2_score is : 0.29115\n",
            "When Lambda (Aplha) value is : 100 \t-> R2_score is : 0.14028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "Alpha_values=[1e-15,1e-13,1e-11,1e-9,1e-7,1e-5,1e-4,1e-3,1e-2,1e-1,0.2,0.3,0.3,0.4,0.5,0.7,0.9,1,2.5,3,5,10,20,30,40,100]\n",
        "\n",
        "# Iterating over the List of Alpha Values to find the Optimal One\n",
        "for i in Alpha_values:\n",
        "    \n",
        "        # Instantiating the Model with different values of i \n",
        "        ridge_model=Ridge(alpha=i, normalize = True, random_state = 42 )\n",
        "        \n",
        "        # Fitting the Model into Training Data \n",
        "        ridge_model.fit(X_train,Y_train)\n",
        "        \n",
        "        # Making Prediction on the Test Data\n",
        "        Y_predicted = ridge_model.predict(X_test)\n",
        "        \n",
        "        # Evaluating the Model :\n",
        "        # We dont use usual \"mean_squared_error\" for Evaluating the Model. We use \"r2_score\" Instead.\n",
        "        score = round(r2_score(Y_test,Y_predicted),5)\n",
        "        \n",
        "        print(\"When Lambda (Aplha) value is :\",i,\"\\t-> R2_score is :\",score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvSlTqYD8j0a"
      },
      "source": [
        "**Let us check the Optimal Value of Lambda with builtin Functions also**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md3xKD6q8j0a",
        "outputId": "5860a6fa-ffb0-4df7-b3ea-423513186f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.81795e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.6901e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.71679e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.70709e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.7791e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Possible Value of Lambda(Alpha) is :  0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "alpha_values={'alpha':Alpha_values}\n",
        "\n",
        "# Instantiating the Model\n",
        "ridge=Ridge(normalize = True,random_state = 42 )\n",
        "\n",
        "ridge_model=GridSearchCV(ridge,alpha_values,scoring='neg_mean_squared_error',cv=5)\n",
        "\n",
        "ridge_model.fit(X_train,Y_train)\n",
        "\n",
        "opt_lambda_r =  ridge_model.best_params_\n",
        "\n",
        "print(\"Best Possible Value of Lambda(Alpha) is : \",opt_lambda_r['alpha'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txfqDXjH8j0a"
      },
      "source": [
        "**So even using the Builtin function `GridSearchCV` gave the same value of Lambda(Alpha)**\n",
        "\n",
        "**So the Optimal Value of Lambda in Ridge Rergession is `0.1` and the Corresponding Score is `0.89056`** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdVibmN8j0a"
      },
      "source": [
        "### Lasso Regression \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3FjOELq8j0a",
        "outputId": "86b584a4-c1b2-4d52-9e7d-8ac4313f9646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 1e-15 \t-> R2_score is : 0.88394\n",
            "When Lambda (Aplha) value is : 1e-13 \t-> R2_score is : 0.88394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 1e-11 \t-> R2_score is : 0.88394\n",
            "When Lambda (Aplha) value is : 1e-09 \t-> R2_score is : 0.88394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 1e-07 \t-> R2_score is : 0.88394\n",
            "When Lambda (Aplha) value is : 1e-05 \t-> R2_score is : 0.88394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.573e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.0001 \t-> R2_score is : 0.88394\n",
            "When Lambda (Aplha) value is : 0.001 \t-> R2_score is : 0.88394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.397e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.01 \t-> R2_score is : 0.88394\n",
            "When Lambda (Aplha) value is : 0.1 \t-> R2_score is : 0.88392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+10, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.215e+09, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.2 \t-> R2_score is : 0.8839\n",
            "When Lambda (Aplha) value is : 0.3 \t-> R2_score is : 0.88386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e+09, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e+09, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.3 \t-> R2_score is : 0.88386\n",
            "When Lambda (Aplha) value is : 0.4 \t-> R2_score is : 0.88382\n",
            "When Lambda (Aplha) value is : 0.5 \t-> R2_score is : 0.88377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+09, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When Lambda (Aplha) value is : 0.7 \t-> R2_score is : 0.88359\n",
            "When Lambda (Aplha) value is : 0.9 \t-> R2_score is : 0.88354\n",
            "When Lambda (Aplha) value is : 1 \t-> R2_score is : 0.88356\n",
            "When Lambda (Aplha) value is : 2.5 \t-> R2_score is : 0.89012\n",
            "When Lambda (Aplha) value is : 3 \t-> R2_score is : 0.89026\n",
            "When Lambda (Aplha) value is : 5 \t-> R2_score is : 0.89087\n",
            "When Lambda (Aplha) value is : 10 \t-> R2_score is : 0.89351\n",
            "When Lambda (Aplha) value is : 20 \t-> R2_score is : 0.8941\n",
            "When Lambda (Aplha) value is : 30 \t-> R2_score is : 0.8925\n",
            "When Lambda (Aplha) value is : 40 \t-> R2_score is : 0.89057\n",
            "When Lambda (Aplha) value is : 100 \t-> R2_score is : 0.87376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "Alpha_values=[1e-15,1e-13,1e-11,1e-9,1e-7,1e-5,1e-4,1e-3,1e-2,1e-1,0.2,0.3,0.3,0.4,0.5,0.7,0.9,1,2.5,3,5,10,20,30,40,100]\n",
        "\n",
        "# Iterating over the List of Alpha Values to find the Optimal One\n",
        "for i in Alpha_values:\n",
        "    \n",
        "        # Instantiating the Model with different values of i \n",
        "        lasso_model=Lasso(alpha=i, normalize = True,random_state = 42 )\n",
        "        \n",
        "        # Fitting the Model into Training Data \n",
        "        lasso_model.fit(X_train,Y_train)\n",
        "        \n",
        "        # Making Prediction on the Test Data\n",
        "        Y_predicted = lasso_model.predict(X_test)\n",
        "        \n",
        "        # Evaluating the Model :\n",
        "        # We dont use usual \"mean_squared_error\" for Evaluating the Model. We use \"r2_score\" Instead.\n",
        "        score = round(r2_score(Y_test,Y_predicted),5)\n",
        "        \n",
        "        print(\"When Lambda (Aplha) value is :\",i,\"\\t-> R2_score is :\",score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSHBspUM8j0b"
      },
      "source": [
        "**Let us check the Optimal Value of Lambda with builtin Functions also**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-q38NS98j0b",
        "outputId": "bf2d05a8-17ab-4671-996e-a6bc8b54dd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.825e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+11, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.878e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.740e+10, tolerance: 5.195e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+11, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+11, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+11, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+11, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.743e+09, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+10, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+10, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.270e+10, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+09, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e+09, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+10, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+08, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+09, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+10, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+08, tolerance: 5.053e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+09, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+10, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+09, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+10, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.836e+08, tolerance: 5.079e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.238e+09, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.513e+09, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+09, tolerance: 5.175e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e+09, tolerance: 5.232e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Possible Value of Lambda(Alpha) is :  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "alpha_values={'alpha':Alpha_values}\n",
        "\n",
        "# Instantiating the Model\n",
        "lasso=Lasso(normalize = True,random_state = 42)\n",
        "\n",
        "lasso_model=GridSearchCV(lasso,alpha_values,scoring='neg_mean_squared_error',cv=5)\n",
        "\n",
        "lasso_model.fit(X_train,Y_train)\n",
        "\n",
        "opt_lambda_l =  lasso_model.best_params_\n",
        "\n",
        "print(\"Best Possible Value of Lambda(Alpha) is : \",opt_lambda_l['alpha'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqRitcTk8j0b"
      },
      "source": [
        "**So even using the Builtin function `GridSearchCV` gave the same value of Lambda(Alpha)**\n",
        "\n",
        "**So the Optimal Value of Lambda in Lasso Rergession is `30` and the Corresponding Score is `0.89303`** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox0mtnP_8j0b"
      },
      "source": [
        "# Lets perform analysis to pick the top 5 features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Squ0natB8j0b"
      },
      "source": [
        "*First lets Determine the optimal value of lambda for ridge and lasso regression.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY_Q-Jv58j0c",
        "outputId": "d3e377bf-4804-4f2f-9592-1428e867bbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Possible Value of Lambda(Alpha) for Ridge Regression is :  0.1\n",
            "Best Possible Value of Lambda(Alpha) for Lasso Regression is :  10\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Possible Value of Lambda(Alpha) for Ridge Regression is : \",opt_lambda_r['alpha'])\n",
        "print(\"Best Possible Value of Lambda(Alpha) for Lasso Regression is : \",opt_lambda_l['alpha'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the optimal values of Lambda for the Ridge & Lasso regression, we got almost similar R2 score. So, we will use Lasso regression with the optimal lambda value for proceeding further."
      ],
      "metadata": {
        "id": "3nvEpetU3kTW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CxpNtpp8j0c"
      },
      "source": [
        "*Now Lets see which features are significant in predicting the price of a house, which inturn helps us in picking top 5 features.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXkLr-BL8j0c",
        "outputId": "e22b8399-d795-4422-b395-c3b2192214ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.464e+11, tolerance: 6.434e+08\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ],
      "source": [
        "# Usual Training the Model with Optimal Lambda\n",
        "\n",
        "lasso_model=Lasso(alpha=opt_lambda_l['alpha'])\n",
        "lasso_model.fit(X_train,Y_train)\n",
        "Y_predicted=lasso_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jxkQzCAF8j0c"
      },
      "outputs": [],
      "source": [
        "# Coefficients found by our Model\n",
        "coefficients= lasso_model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "k9HvFb0P8j0c"
      },
      "outputs": [],
      "source": [
        "# List of Columns used for Training\n",
        "columns = houses_data.loc[:, houses_data.columns != 'SalePrice'].columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "hbBvDj_W8j0d"
      },
      "outputs": [],
      "source": [
        "# Creating a Dictionary which has Keys as Column Names and Values as Coefficient of that particular Variable found by Model\n",
        "\n",
        "col_coef =  zip(columns,coefficients)\n",
        "col_coef_dict =  dict(col_coef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUd_w3pc8j0d",
        "outputId": "269ac24e-ef06-4bdf-9327-a79f34a2488e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 25 Significant Variables in predicting the price of a house are :-\n",
            " ['LandSlope', 'OverallQual', 'GarageCars', 'OverallCond', 'Fireplaces', 'Functional', 'LandContour', 'MasVnrType', 'SaleCondition', 'Foundation', 'GarageCond', 'BsmtFullBath', 'ExterCond', 'PavedDrive', 'RoofMatl', 'Exterior2nd', 'BsmtCond', 'HalfBath', 'TotRmsAbvGrd', 'BsmtFinType2', 'Neighborhood', 'MoSold', 'LotConfig', 'YearBuilt', 'FullBath']\n"
          ]
        }
      ],
      "source": [
        "# Sorting the Elements in the Dictionary in Descending order with Keys\n",
        "\n",
        "sorted_col_coef_dict = dict( sorted(col_coef_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
        "\n",
        "significant_col = list(sorted_col_coef_dict.keys())\n",
        "\n",
        "print('The top 25 Significant Variables in predicting the price of a house are :-\\n',significant_col[:25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8qTGZl58j0d"
      },
      "source": [
        "**So we will take Top Five features which are as follows:**\n",
        "\n",
        "**'LandSlope', 'OverallQual', 'GarageCars', 'OverallCond', 'Fireplaces'**\n",
        "\n",
        "**Now lets make a function that can be embedded in the Flask web app to make prediction on the user input.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import Ridge,Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def predict_price():\n",
        "    houses_data = pd.read_csv(\"train.csv\")\n",
        "    houses_data.drop(['Id','Alley', 'PoolQC', 'Fence', 'MiscFeature','FireplaceQu'], axis=1, inplace=True)\n",
        "    columns_with_null =  houses_data.isnull().sum()[lambda x : x>0].index.values.tolist()\n",
        "\n",
        "    for col in columns_with_null :\n",
        "      houses_data[col].fillna(houses_data[col].mode()[0], inplace=True)\n",
        "\n",
        "    Non_Numerical_Columns = houses_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "    for col in Non_Numerical_Columns:\n",
        "      lb=LabelEncoder()\n",
        "      houses_data[col]=lb.fit_transform(houses_data[col])\n",
        "\n",
        "    Y = houses_data[['SalePrice']].values\n",
        "    X = houses_data.loc[:, houses_data.columns != 'SalePrice'].values\n",
        "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,random_state= 20)\n",
        "    X_train = houses_data.loc[:,['LandSlope', 'OverallQual', 'GarageCars', 'OverallCond', 'Fireplaces']].values\n",
        "    Y_train =  houses_data.loc[:,['SalePrice']].values\n",
        "    lasso_model=Lasso(alpha=opt_lambda_l['alpha'])\n",
        "    lasso_model.fit(X_train,Y_train)\n",
        "    testing_Data =pd.read_csv(\"test.csv\")\n",
        "    testing_Data = testing_Data.loc[:,['LandSlope', 'OverallQual', 'GarageCars', 'OverallCond', 'Fireplaces']]\n",
        "    lb=LabelEncoder() \n",
        "    print(testing_Data.head())\n",
        "    testing_Data['LandSlope']=lb.fit_transform(testing_Data['LandSlope'])\n",
        "    print(testing_Data.head())\n",
        "    columns_with_null =  testing_Data.isnull().sum()[lambda x : x>0].index.values.tolist()\n",
        "    for col in columns_with_null :\n",
        "      testing_Data[col].fillna(testing_Data[col].mode()[0], inplace=True)\n",
        "\n",
        "    X_test = testing_Data.loc[:,['LandSlope', 'OverallQual', 'GarageCars', 'OverallCond', 'Fireplaces']].values\n",
        "    Y_predicted = lasso_model.predict(X_test)\n",
        "    return Y_predicted"
      ],
      "metadata": {
        "id": "bYNu8l0e61Ql"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_price()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDazUMnfOdio",
        "outputId": "c4558f51-6407-46f9-d750-d84f3ac1fa6c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  LandSlope  OverallQual  GarageCars  OverallCond  Fireplaces\n",
            "0       Gtl            5         1.0            6           0\n",
            "1       Gtl            6         1.0            6           0\n",
            "2       Gtl            5         2.0            5           1\n",
            "3       Gtl            6         2.0            6           1\n",
            "4       Gtl            8         2.0            5           0\n",
            "   LandSlope  OverallQual  GarageCars  OverallCond  Fireplaces\n",
            "0          0            5         1.0            6           0\n",
            "1          0            6         1.0            6           0\n",
            "2          0            5         2.0            5           1\n",
            "3          0            6         2.0            6           1\n",
            "4          0            8         2.0            5           0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([111743.8723941 , 145716.47113411, 154492.33731312, ...,\n",
              "       158014.80132086,  83981.62353381, 269080.6135245 ])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zenoOFBTDO5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Assignment For Internship - Siemens.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3Vw6ByZL7bsE",
        "I3Qy7voQ8j0E",
        "2lV4Abyk8j0R",
        "_sHz-jMd8j0T"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
